# Wissenschaftliche Trends Analyse

## Projektbeschreibung

Dieses Projekt analysiert wissenschaftliche Artikel aus dem arXiv-Datensatz, um aktuelle Trends in der Wissenschaft zu identifizieren. Die Analyse wurde im Rahmen einer Fallstudie f√ºr un√ºberwachtes Lernen entwickelt und zielt darauf ab, Einblicke in aktuelle Forschungsschwerpunkte zu geben.

## Aufgabenstellung

Das Unternehmen m√∂chte sich st√§rker in Richtung Forschung und akademische Zusammenarbeit positionieren. Dazu soll ein umfassender quantitativer √úberblick √ºber aktuelle Themen in der Wissenschaft erstellt werden, basierend auf einem gro√üen Archiv wissenschaftlicher Arbeiten.

## Methodischer Ansatz

### 1. Datenexploration
- Analyse der Datensatz-Struktur
- Deskriptive Statistiken
- Visualisierung der Datenverteilung
- Identifikation von Datenqualit√§tsproblemen

### 2. Textvorverarbeitung
- **Textreinigung**: Entfernung von LaTeX-Formeln, Sonderzeichen und Normalisierung
- **Tokenisierung**: Regex-basierte Tokenisierung ohne NLTK-Abh√§ngigkeiten
- **Stopword-Entfernung**: Erweiterte Liste mit wissenschaftlichen Begriffen (paper, study, research, etc.)
- **Feature-Engineering**: TF-IDF mit 2000 Features und N-Grammen (1,3)

### 3. Feature Engineering
- **TF-IDF Vektorisierung**: Konvertierung von Text zu numerischen Features
- **Feature-Anzahl**: 2000 Features f√ºr alle Analysen (Hauptanalyse und detaillierte Cluster-Analyse)
- **N-Gramme**: Unigramme, Bigramme und Trigramme (1,3)
- **Feature-Selektion**: Automatische Auswahl der wichtigsten Begriffe

### 4. Dimensionsreduktion
- **TruncatedSVD**: Dimensionsreduktion f√ºr gro√üe sparse Matrizen (100 Komponenten ‚âà 70% Varianz)
- **t-SNE**: Nicht-lineare Dimensionsreduktion f√ºr Visualisierung (erste 15 SVD-Komponenten)
- **Speichereffizienz**: Direkte Verarbeitung von TF-IDF-Matrizen ohne .toarray()

### 5. Clustering-Analyse
- **K-Means**: Standard-Clustering-Algorithmus mit automatischer Silhouette-Score-Optimierung
- **AgglomerativeClustering**: Empfohlener Algorithmus f√ºr die Fallstudie mit n_clusters=6 (Standard) oder 7 (empfohlen)
- **Cluster-Labels**: Automatische Generierung sprechender Beschriftungen
- **Validierung**: Manuelle √úberpr√ºfung und quantitative Bewertung

### 6. Topic Modeling
- **LDA (Latent Dirichlet Allocation)**: Identifikation latenter Themen in den Dokumenten
- **Topic-Extraktion**: Automatische Erkennung wissenschaftlicher Forschungsbereiche

## Installation und Ausf√ºhrung

### Voraussetzungen
- Python 3.8 oder h√∂her
- pip (Python Package Manager)

### Installation der Abh√§ngigkeiten
```bash
pip install -r requirements.txt
```

### Ausf√ºhrung der Analyse
```bash
python wissenschaftliche_trends_analyse.py
```

## Projektstruktur

```
UnsupervisedLearning/
‚îú‚îÄ‚îÄ arxiv_daten_analyse.py              # Hauptskript f√ºr arXiv-Analyse
‚îú‚îÄ‚îÄ wissenschaftliche_trends_analyse.py # Alternative Analyse-Skript
‚îú‚îÄ‚îÄ methodische_entscheidungen.md       # Dokumentation der methodischen Entscheidungen
‚îú‚îÄ‚îÄ requirements.txt                    # Python-Abh√§ngigkeiten
‚îú‚îÄ‚îÄ README.md                           # Diese Dokumentation
‚îú‚îÄ‚îÄ Output/                             # Ausgabe-Ordner f√ºr alle Ergebnisse
‚îÇ   ‚îú‚îÄ‚îÄ *.png                           # Visualisierungen
‚îÇ   ‚îú‚îÄ‚îÄ *.json                          # JSON-Exporte
‚îú‚îÄ‚îÄ .gitignore                          # Git-Ignore-Datei
‚îî‚îÄ‚îÄ arxiv-metadata-oai-snapshot.json    # arXiv-Datensatz (4,5 GB)
```
**Hinweis:** Die Datei `arxiv-metadata-oai-snapshot.json` (4,4‚ÄØGB) ist in `.gitignore` ausgeschlossen und wird nicht mitversioniert.



## Ausgaben

### üìä Visualisierungen (im `Output/`-Ordner)
- **`arxiv_kategorien.png`**: Top 15 arXiv-Kategorien (einheitliche Farbpalette)
- **`arxiv_jahrgang.png`**: Zeitliche Verteilung der Publikationen
- **`abstract_laengen.png`**: Verteilung und Boxplot der Abstract-L√§ngen
- **`arxiv_top_features.png`**: Top 30 TF-IDF Features mit Farbverlauf
- **`tsne_vor_clustering.png`**: t-SNE vor Clustering (grau)
- **`tsne_nach_clustering.png`**: t-SNE nach Clustering (farbig, Cluster)
- **`arxiv_trend_entwicklung.png`**: Zeitliche Entwicklung der Cluster
- **`arxiv_topic_verteilung.png`**: LDA Topic-Verteilung

### üìÑ Daten-Exporte (im `Output/`-Ordner)
- **`cluster_summary.json`**: Cluster-Zusammenfassung (Gr√∂√üen, Top-W√∂rter, Trends)
- **`cluster_detaillierte_analyse.json`**: Detaillierte Cluster-Analyse mit Kernaussagen
- **`arxiv_trends_ergebnisse.csv`**: Vollst√§ndige Ergebnisse als CSV

### üîç Cluster-Analyse
- **6 Cluster** werden standardm√§√üig automatisch identifiziert
- **7 Cluster** empfohlen f√ºr die Fallstudie (explizit angeben)
- **Dynamische Labels** basierend auf Top-W√∂rtern jedes Clusters
- **Cluster-Gr√∂√üen** variieren je nach Zufalls-Sampling
- **Detaillierte Analyse** mit Kernaussagen f√ºr jeden Cluster

## Technische Details

### Verwendete Bibliotheken
- **pandas**: Datenmanipulation und -analyse
- **numpy**: Numerische Berechnungen
- **scikit-learn**: Machine Learning Algorithmen
- **matplotlib/seaborn**: Visualisierung
- **scipy**: Wissenschaftliche Berechnungen
- **regex**: Textverarbeitung (ohne NLTK-Downloads)

### Algorithmen
1. **TF-IDF Vectorizer**: Text-zu-Vektor-Konvertierung mit 2000 Features
2. **TruncatedSVD**: Dimensionsreduktion f√ºr gro√üe sparse Matrizen
3. **t-SNE**: Nicht-lineare Dimensionsreduktion f√ºr Visualisierung
4. **K-Means**: Standard-Clustering-Algorithmus mit Silhouette-Optimierung
5. **AgglomerativeClustering**: Empfohlener Clustering-Algorithmus f√ºr Fallstudie
6. **LDA**: Topic Modeling

### Parameter-Optimierung
- **K-Means**: Standard mit automatischer Silhouette-Score-Optimierung (2-10 Cluster)
- **AgglomerativeClustering**: Empfohlen f√ºr Fallstudie mit n_clusters=6 (Standard) oder 7 (empfohlen)
- **Manuelle Validierung**: Stichprobenartige √úberpr√ºfung der Cluster-Qualit√§t

### Verf√ºgbare Clustering-Methoden
```python
# Standard (K-Means mit automatischer Optimierung):
analysator.clustering_analyse(method='kmeans')

# Empfohlen f√ºr Fallstudie (AgglomerativeClustering):
analysator.clustering_analyse(method='agglomerative', n_clusters=7)

# Alternative (AgglomerativeClustering mit 6 Clustern):
analysator.clustering_analyse(method='agglomerative')
```

## Ergebnisse und Interpretation

### Cluster-Charakterisierung
- **Automatische Identifikation** wissenschaftlicher Trends basierend auf TF-IDF-Analyse
- **Dynamische Cluster-Labels** werden aus den Top-W√∂rtern jedes Clusters generiert
- **Inhaltliche Profile** mit Kernaussagen f√ºr jeden identifizierten Cluster
- **Zeitliche Entwicklung** der Cluster √ºber die analysierten Jahre

### Empfehlungen f√ºr akademische Kooperationen
Basierend auf der Cluster-Analyse werden spezifische Empfehlungen f√ºr potenzielle Kooperationsbereiche gegeben, die sich an den identifizierten Trends orientieren.

## Gesellschaftliche und ethische √úberlegungen

### Positive Auswirkungen
- **Transparenz**: Besseres Verst√§ndnis aktueller Forschungstrends
- **Strategische Planung**: Datenbasierte Entscheidungen f√ºr Kooperationen
- **Wissensverbreitung**: Identifikation relevanter Forschungsbereiche

### Ethische √úberlegungen
- **Datenschutz**: Sorgf√§ltige Behandlung wissenschaftlicher Daten
- **Transparenz**: Offenlegung der verwendeten Methoden
- **Bias-Bewusstsein**: Ber√ºcksichtigung m√∂glicher Verzerrungen in den Daten

### Nachhaltigkeitsaspekte
- **Ressourceneffizienz**: Fokus auf umweltrelevante Forschungsthemen
- **Langfristige Perspektive**: Ber√ºcksichtigung nachhaltiger Entwicklungen

## Qualit√§tssicherung

### Validierung der Ergebnisse
- **Silhouette-Score**: Quantitative Bewertung der Cluster-Qualit√§t (nur f√ºr KMeans)
- **Manuelle √úberpr√ºfung**: Stichprobenartige Kontrolle der Cluster-Zuordnungen
- **Automatische Cluster-Labels**: Sprechende Beschriftungen basierend auf Top-W√∂rtern
- **Detaillierte Cluster-Analyse**: Kernaussagen und inhaltliche Profile f√ºr jeden Cluster

### Kritische Reflexion
- **Methodenwahl**: Begr√ºndung der gew√§hlten Algorithmen
- **Parameter-Optimierung**: Transparente Dokumentation der Optimierungsschritte
- **Limitationen**: Offenlegung der Grenzen der Analyse

## Erweiterungsm√∂glichkeiten

### Technische Verbesserungen
- **Deep Learning**: Verwendung von Word Embeddings (Word2Vec, BERT)
- **Alternative Clustering-Algorithmen:** Neben KMeans steht jetzt auch AgglomerativeClustering (hierarchisch) zur Verf√ºgung.
- **Nutzung:** Die Methode kann beim Aufruf von `clustering_analyse(method='agglomerative')` gew√§hlt werden.
- **Vorteile:** AgglomerativeClustering liefert hierarchische Strukturen und ist robuster gegen√ºber Ausrei√üern als KMeans.
- **Zeitreihenanalyse**: Detailliertere Trend-Analyse √ºber Zeit

### Inhaltliche Erweiterungen
- **Mehrsprachige Analyse**: Einbeziehung nicht-englischer Publikationen
- **Interdisziplin√§re Trends**: Analyse von Schnittstellen zwischen Bereichen
- **Impact-Analyse**: Ber√ºcksichtigung von Zitierungen und Impact-Faktoren

## Fazit

Diese Analyse demonstriert die Anwendung verschiedener Techniken des un√ºberwachten Lernens zur Identifikation wissenschaftlicher Trends. Durch die Kombination von Text-Mining, Dimensionsreduktion und Clustering konnten aussagekr√§ftige Einblicke in aktuelle Forschungsschwerpunkte gewonnen werden.

Die Ergebnisse liefern eine solide Grundlage f√ºr strategische Entscheidungen im Bereich akademischer Kooperationen und zeigen das Potenzial datengetriebener Ans√§tze in der Wissenschaftsanalyse.

---

**Autor**: Maria Auer  
**Datum**: 28.07.2025  
**Projekt**: Fallstudie DLBDSMLUSL01_D - Un√ºberwachtes Lernen